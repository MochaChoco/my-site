---
title: "대용량 엑셀 다운로드: 클라이언트에서 서버로"
description: "클라이언트 기반 엑셀 생성의 한계를 극복하고 SSE를 활용한 서버 사이드 아키텍처로 성능과 사용자 경험을 개선한 경험을 공유합니다."
date: "2025-01-04"
tags: ["react", "performance", "maintenance"]
slug: "excel-download-refectoring"
coverImage: "/images/posts/excel-download-refectoring/cover.png"
---

![커버 이미지](/images/posts/excel-download-refectoring/cover.png)

안녕하세요! 이번 글에서는 한 관리형 대시보드 프로젝트에서 대용량 엑셀 다운로드 기능을 획기적으로 개선했던 경험을 공유하고자 합니다. 복잡한 문제를 해결하며 얻은 기술적 깨달음과 시스템 안정화를 위한 고민들을 담아보았습니다.

## 대용량 엑셀 다운로드, 클라이언트의 비명

개발팀은 운영 툴에서 대용량 데이터를 엑셀이나 CSV로 다운로드하는 기능을 꾸준히 제공해왔습니다. 처음에는 간단한 로직으로 구현되었지만, 시간이 지나면서 처리해야 할 데이터의 양이 기하급수적으로 늘어나자 기존 방식의 한계에 부딪히기 시작했습니다.

이전에는 모든 엑셀 다운로드 로직이 클라이언트 브라우저에서 직접 데이터를 수집하고 파일을 생성하는 방식으로 동작했습니다. 수십만 건에 달하는 데이터를 웹 브라우저 메모리에 한꺼번에 로드하고 ExcelJS 같은 라이브러리로 워크북을 생성하려니 문제가 심각했습니다.

가장 흔하게 겪었던 문제들은 다음과 같았습니다:

- **브라우저 메모리 폭증 및 UI 멈춤**: 대용량 데이터를 처리하는 동안 브라우저 탭이 멈추거나, "응답 없음" 상태가 되어 사용자가 기다리다 지쳐 탭을 닫아버리는 일이 비일비재했습니다.
- **낮은 사양 기기에서의 실패**: 고사양 데스크톱에서는 겨우 버틸지 몰라도, 모바일 기기나 저사양 노트북에서는 아예 파일 생성이 실패하는 경우가 많았습니다.
- **긴 생성 시간과 불확실성**: 수 분에서 길게는 십 분 이상 소요되는 작업임에도 불구하고, 사용자에게는 아무런 피드백 없이 흰 화면만 보여주어 답답함을 유발했습니다. 작업이 완료될 때까지 기다려야 하는지, 아니면 실패한 것인지 알 수 없었죠.
- **네트워크 재시도 및 오류 처리의 어려움**: 클라이언트 측에서는 데이터 수집 중 네트워크 문제나 백엔드 API의 일시적인 오류 발생 시 재시도 로직을 견고하게 구현하기가 어렵습니다.
- **타임아웃 및 취소 처리의 한계**: 브라우저에 따라 HTTP 요청 타임아웃이 발생하거나, 사용자가 강제로 페이지를 닫는 경우 불완전한 작업이 남을 수 있었습니다.
- **데이터 정합성 문제**: 클라이언트에서 데이터를 페이징으로 가져오는 과정에서 혹시 모를 누락이나 중복 발생 시 서버 측에서 제어하기 어렵다는 구조적인 한계도 있었습니다.

결국, 대용량 엑셀 다운로드 기능은 사용자 경험을 저해하는 주범이자, 개발팀에게도 유지보수 및 디버깅에 큰 부담을 주는 골칫덩이가 되어가고 있었습니다. 이러한 문제점들을 해결하기 위해 서버 사이드 아키텍처 개선과 SSE(Server-Sent Events) 적용을 결정하게 되었습니다.

## 대용량 데이터 처리의 새로운 접근: 서버 사이드 비동기 & SSE

기존 방식의 한계를 절감하고, 우리는 대용량 엑셀 다운로드 로직을 클라이언트 브라우저에서 서버 사이드로 완전히 이전하기로 결정했습니다. 이와 함께 사용자 경험 개선을 위해 실시간 진행률 알림 기능을 도입하는 것을 목표로 삼았습니다.

### 핵심 개념과 기술 선택 배경

새로운 아키텍처를 설계하면서 다음과 같은 기술 개념들을 활용했습니다. 각 기술이 어떤 역할을 하고 왜 선택되었는지 설명해 드릴게요.

#### 1. Server-Sent Events (SSE)로 실시간 소통하기

데이터 수집과 파일 생성은 서버에서 진행되므로, 클라이언트에게는 작업의 진행 상태를 실시간으로 알려줄 방법이 필요했습니다. 여기서 `Server-Sent Events (SSE)`가 빛을 발했습니다.

SSE는 서버가 클라이언트에게 단방향으로 이벤트를 푸시하는 웹 기술입니다. HTTP 프로토콜 위에 구축되며, `EventSource` 인터페이스를 통해 클라이언트와 연결을 설정하고 `text/event-stream` 미디어 타입을 사용하여 데이터를 스트리밍합니다. 우리는 대용량 엑셀 다운로드처럼 서버에서 장시간 소요되는 작업의 실시간 진행률을 사용자에게 투명하게 제공하여 사용자 경험을 대폭 개선하기 위해 SSE를 선택했습니다.

- **Polling 방식과의 차이**: 클라이언트가 주기적으로 서버에 업데이트를 요청하는 폴링 방식은 구현은 간단하지만, 잦은 요청으로 서버 부하를 유발하고 실시간성이 떨어집니다. 대용량 엑셀 다운로드처럼 진행 상태가 지속적으로 변하는 경우 비효율적이죠. 반면 SSE는 서버가 새로운 데이터를 생성할 때마다 클라이언트에 자동으로 푸시하므로 훨씬 효율적입니다.
- **WebSocket과의 차이**: 웹소켓은 양방향 통신이 필요한 채팅이나 게임 등에 적합한 전이중(full-duplex) 프로토콜입니다. 하지만 엑셀 다운로드 진행률처럼 클라이언트가 서버에 데이터를 보낼 필요 없이 서버의 업데이트만 받으면 되는 단방향 통신 상황에서는 웹소켓보다 가볍고 구현이 간단한 SSE가 훨씬 효율적인 선택입니다. 브라우저에서 자동으로 재연결을 시도하는 기능도 내장하고 있어 안정성도 뛰어납니다.

#### 2. Next.js Route Handlers로 모듈화된 API 구축

Next.js 13+의 App Router 환경에서 API 엔드포인트를 생성하는 `Route Handlers`는 기존의 모놀리식 API 구조를 해체하는 데 핵심적인 역할을 했습니다. `app` 디렉토리 내에 `route.ts` 파일을 생성하여 특정 경로에 대한 서버 사이드 로직을 정의할 수 있습니다. 각 HTTP 메소드에 해당하는 함수를 `export`함으로써 해당 메소드의 요청을 처리합니다.

우리는 기존의 단일 API 엔드포인트(`app/api/download/route.ts`)를 여러 개의 전용 Route Handler(`app/api/excel/[type]/route.ts`)로 분리하여 코드의 모듈화와 유지보수성을 극대화했습니다. Next.js의 파일 시스템 기반 라우팅을 활용하여 각 엑셀 다운로드 타입별로 독립적인 엔드포인트를 구성함으로써, 특정 타입의 로직 변경이 다른 타입에 미치는 영향을 최소화할 수 있었습니다.

#### 3. ExcelJS로 서버에서 엑셀 파일 생성

브라우저 환경에서 겪었던 메모리 폭증 문제를 해결하기 위해, `ExcelJS` 라이브러리를 사용하여 서버 환경(Node.js)에서 엑셀 파일을 생성하도록 변경했습니다. ExcelJS는 워크북, 워크시트, 셀 데이터를 유연하게 제어하며 다양한 Excel 기능을 지원하는 강력한 라이브러리입니다.

특히 대용량 데이터를 처리할 때는 스트리밍 방식으로 메모리 사용량을 최적화하는

#### 4. 비동기 및 청크/배치 처리로 효율 극대화

데이터 수집 및 엑셀 파일 생성은 시간이 오래 걸리는 작업이므로, 이들을 **비동기적으로 처리**하여 서버의 응답성을 유지하는 것이 중요했습니다. JavaScript의 `async`/`await` 구문을 적극 활용하여 장시간 작업을 백그라운드에서 실행하고, 메인 스레드를 블로킹하지 않도록 설계했습니다.

또한, 대용량 데이터를 한 번에 메모리에 로드하거나 처리하지 않고, `청크(Chunk)` 또는 `배치(Batch)` 단위로 나누어 순차적으로 처리하는 방식을 도입했습니다. 이를 통해 메모리 사용량을 최적화하고, 프로세서에 과도한 부하가 걸리는 것을 방지하며, 장시간 소요되는 작업의 중간 진행 상황을 SSE를 통해 클라이언트에 보고할 수 있게 했습니다. `data-fetcher` 모듈의 페이징 처리와 `generator` 모듈의 `processDataInBatches` 유틸리티가 이 역할을 담당합니다.

#### 5. 데이터베이스 연결 풀 관리를 고려한 견고한 데이터 수집

직접적인 데이터베이스 연결 풀을 구현하지는 않았지만, `data-fetcher` 모듈에 포함된 `SHORT_DELAY`, `LONG_DELAY`, `MAX_RETRIES`, `RETRY_DELAY`와 같은 설정들은 간접적으로 데이터베이스 연결 풀의 부하를 분산하고 안정적인 운영에 기여하는 전략적인 접근입니다. 대용량 데이터 조회 시 DB에 가해지는 과도한 요청을 완화하고, 네트워크 지연이나 일시적인 DB 장애 시에도 안정적으로 데이터를 가져올 수 있도록 재시도 로직을 포함하여 "견고한 데이터 수집" 설계를 완성했습니다.

## 구현 포인트: 모놀리식 구조 해체와 모듈화

이번 리팩토링의 핵심은 약 2,500줄에 달하는 거대한 모놀리식 코드(`app/api/download/route.ts` 및 `libs/excelDownload.js`)를 해체하고, Next.js Route Handler를 기반으로 한 모듈화된 아키텍처로 전환하는 것이었습니다.

### 변경 전: 모든 것을 담고 있던 단일 엔드포인트

이전에는 모든 엑셀/CSV 다운로드 요청이 `type` 파라미터로 다운로드 타입을 구분하는 단일 `/api/download` 엔드포인트로 전송되었습니다. 데이터 수집 로직, 파일 생성 로직, 그리고 SSE 진행 상황 푸시 로직까지 모두 이 파일 내부에 구현되어 있었죠. 이로 인해 코드의 결합도가 극도로 높아 유지보수가 매우 어려웠습니다.

```typescript
// ... 데이터 수집 및 ExcelJS 관련 유틸리티 함수들이 이 파일 내부에 모두 정의되어 있었음 ...

const DataFetchSettings = {
  BATCH_SIZE: 50,
  SHORT_DELAY: 10,
  LONG_DELAY: 500,
  MAX_RETRIES: 3,
  RETRY_DELAY: 1000,
};

// 내부 정의된 페이징 데이터 수집 함수
async function fetchPaginatedData(
  fetchFunction: (params: any) => Promise<any>,
  params: Record<string, any>,
  outputType: string | undefined,
  onProgress: (data: any) => void
): Promise<any[]> {
  const allData: any[] = [];
  let hasMore = true;
  let page = 0;
  const itemsPerPage = 200;
  const startTime = Date.now();

  const { BATCH_SIZE, SHORT_DELAY, LONG_DELAY, MAX_RETRIES } =
    DataFetchSettings;

  while (hasMore) {
    let attempts = 0;
    let success = false;
    while (attempts < MAX_RETRIES && !success) {
      try {
        const result = await fetchFunction({
          ...params,
          page: page.toString(),
          itemsPerPage: itemsPerPage.toString(),
          ...(outputType && { outputType }),
        });
        const items = result?.elements ?? result?.items ?? [];
        hasMore = result?.hasNext ?? false;
        allData.push(...items);

        onProgress({
          type: "progress",
          currentPage: page + 1,
          collectedItems: allData.length,
          hasNext: hasMore,
          elapsedTime: Math.floor((Date.now() - startTime) / 1000),
        });

        success = true;
        page++;
        if (hasMore && page % BATCH_SIZE === 0) {
          await new Promise((resolve) => setTimeout(resolve, LONG_DELAY));
        } else if (hasMore) {
          await new Promise((resolve) => setTimeout(resolve, SHORT_DELAY));
        }
      } catch (error) {
        attempts++;
        if (attempts < MAX_RETRIES) {
          /* ... 재시도 로직 ... */
        } else {
          throw error;
        }
      }
    }
  }
  return allData;
}

// 내부 정의된 엑셀/CSV 생성 함수 (예시)
async function createExcelDocument(
  type: string,
  data: any[],
  dateFilter: string,
  metaList: any[],
  onProgress: (data: any) => void,
  category?: string
) {
  // ... ExcelJS를 이용한 워크북 및 워크시트 생성 로직 ...
  // ... data를 순회하며 셀 데이터 및 스타일 설정 ...
  // ... onProgress로 진행률 푸시 ...
  // return workbook;
}

export async function POST(request: Request) {
  const { searchParams } = new URL(request.url);
  const type = searchParams.get("type"); // 경로 파라미터로 다운로드 타입 구분
  const body = await request.json();

  const params = body.params || {};
  const metaList = body.metaList || [];
  const endpointConfig = {
    fetchFunction: "fetchRecords",
    type: "excel",
  }; // 실제로는 동적으로 매핑

  const textEncoder = new TextEncoder();
  const responseStream = new ReadableStream({
    async start(controller) {
      const onProgress = (data: any) => {
        const message = `data: ${JSON.stringify(data)}\n\n`;
        controller.enqueue(textEncoder.encode(message));
      };

      try {
        onProgress({
          type: "stage",
          stage: "collecting",
          message: "Data collection in progress...",
        });
        const data = await fetchPaginatedData(
          endpointConfig.fetchFunction,
          params,
          endpointConfig.type,
          onProgress
        );

        if (data.length === 0) {
          onProgress({ type: "error", message: "No data found." });
          controller.close();
          return;
        }

        if (type && type.endsWith("_csv")) {
          // 내부 정의된 CSV 생성 함수 호출
          const workbook = await createExcelDocument(
            type,
            data,
            metaList,
            onProgress
          );
          const buffer = await workbook.csv.writeBuffer();
          const base64 = Buffer.from(buffer).toString("base64");
          onProgress({
            type: "complete",
            fileData: base64,
            dataType: "csv",
          });
        } else {
          // 내부 정의된 Excel 생성 함수 호출
          const workbook = await createExcelDocument(
            type,
            data,
            "",
            metaList,
            onProgress
          );
          const buffer = await workbook.writeToBuffer();
          const base64 = Buffer.from(buffer).toString("base64");
          onProgress({
            type: "complete",
            fileData: base64,
            dataType: "excel",
          });
        }
        controller.close();
      } catch (error) {
        onProgress({
          type: "error",
          message: "Download failed.",
          error: error instanceof Error ? error.message : String(error),
        });
        controller.close();
      }
    },
  });
  return new Response(responseStream, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    },
  });
}
```

이전 코드에서는 `fetchPaginatedDataInternal`, `createExcelDocumentInternal`과 같은 데이터 수집 및 파일 생성 로직이 모두 단일 Route Handler 파일 내부에 정의되어 있었습니다. `downloadType` 쿼리 파라미터에 따라 내부적으로 로직을 분기하는 방식이었죠. 이러한 구조는 기능 추가나 수정 시 전체 파일에 영향을 미칠 수 있고, 각 기능의 책임이 불분명하며, 테스트도 어려웠습니다. 또한, Next.js의 파일 기반 라우팅 이점을 충분히 활용하지 못하는 구조였습니다.

### 변경 후: 모듈화된 Route Handler와 재사용 가능한 유틸리티

리팩토링 후에는 각 다운로드 타입(예: `typeA`, `typeB`)별로 독립적인 Next.js Route Handler가 생성되었습니다. 이 핸들러들은 데이터 수집, SSE 스트림 관리, 파일 생성 등 공통 로직을 별도의 `libs/excel` 디렉토리로 분리된 유틸리티 함수들을 활용합니다. 이를 통해 코드의 재사용성을 높이고, 특정 타입의 로직 변경이 다른 타입에 영향을 미치지 않도록 하여 유지보수성과 확장성을 크게 향상시켰습니다.

```typescript
// app/api/excel/typeA/route.ts (실시간 데이터 엑셀 다운로드 핸들러 예시)

import {
  initializeSSEStream,
  EventStreamHandler,
} from "@/libs/excel/stream-handler";
import { fetchPaginatedData } from "@/libs/excel/data-fetcher";
import {
  createExcelWorkbook,
  setColumnWidths,
  processDataInBatches,
  dispatchExcelFile,
  StylingPresets,
} from "@/libs/excel/generator";
import { fetchTypeARecords } from "../../data-logic/typeA/logic"; // 각 핸들러에 특화된 데이터 조회 로직

export async function POST(request: Request) {
  const body = await request.json();

  const params = body.params || {};
  const metaList = body.metaList || [];

  // SSE 스트림 초기화 및 EventStreamHandler 인스턴스 획득
  return initializeSSEStream(async (eventStreamHandler: EventStreamHandler) => {
    eventStreamHandler.publish({
      type: "stage",
      stage: "collecting",
      message: "데이터 수집을 시작합니다...",
    });

    // 1. 공통 데이터 페처 유틸리티를 사용하여 데이터 수집

    const data = await fetchPaginatedData(
      fetchTypeARecords, // 각 핸들러에 특화된 데이터 조회 함수 전달
      params,
      eventStreamHandler, // 진행 상황 푸시를 위한 핸들러 전달
      { itemsPerPage: 200, outputType: "excel" }
    );

    if (data.length === 0) {
      eventStreamHandler.publish({
        type: "error",
        message: "출력할 데이터가 없습니다.",
      });
      return;
    }

    eventStreamHandler.publish({
      type: "stage",
      stage: "generating",
      message: "엑셀 파일 생성을 시작합니다",
    });

    // 비동기 작업 스케줄링을 위한 짧은 지연
    await new Promise((resolve) => setImmediate(resolve));

    // 2. 공통 워크북 생성 유틸리티

    const { workbook, worksheet } = createExcelWorkbook("데이터_시트");

    setColumnWidths(
      worksheet,
      [10, 18, 50, 15, 15, 18, 15, 15, 20, 50, 12, 10, 10, 10, 16, 10]
    );

    const headers = [
      "NO",
      "필드1",
      "필드2",
      "필드3",
      "필드4",
      // ... 기타 필드명 ...
    ];

    headers.forEach((headerText, index) => {
      const cell = worksheet.getCell(1, index + 1);
      cell.value = headerText;
      cell.style = StylingPresets.header; // 공통 스타일 유틸리티
    });

    // 3. 공통 청크 처리 유틸리티를 사용하여 데이터 순회 및 셀 설정

    await processDataInBatches(
      data,
      500, // 청크 사이즈
      (batch, startIdx) => {
        batch.forEach((item, idx) => {
          const rowNumber = startIdx + idx + 2;
          const row = worksheet.getRow(rowNumber);
          // ... 셀 값 및 스타일 설정 ...
          row.commit();
        });
      },
      eventStreamHandler,
      "엑셀 파일 생성 중"
    );

    // 4. 공통 파일 전송 유틸리티를 사용하여 다운로드 준비 완료
    await dispatchExcelFile(workbook, eventStreamHandler, data.length);
  });
}
```

개선된 Route Handler는 `initializeSSEStream` 함수를 호출하여 SSE 연결을 설정하고, 내부에서 비동기 `handler` 함수를 실행합니다. 이 `handler`는 `EventStreamHandler` 인스턴스를 받아 진행 상황을 클라이언트에 푸시하며, `fetchPaginatedData`로 데이터를 수집하고, `createExcelWorkbook`, `processDataInBatches`, `dispatchExcelFile`과 같은 공통 유틸리티들을 순서대로 호출하여 엑셀 파일을 생성하고 전송합니다. 각 단계별로 SSE를 통해 사용자에게 "데이터 수집 중", "엑셀 파일 생성 중"과 같은 메시지를 전달합니다.

### SSE 스트림 관리 유틸리티: `stream-handler.ts`

SSE를 효율적으로 관리하기 위해 별도의 `EventStreamHandler` 클래스와 `initializeSSEStream` 유틸리티를 구현했습니다. 이 모듈은 서버가 클라이언트에게 실시간 진행 상황을 푸시하는 역할을 담당합니다.

```typescript
// libs/excel/stream-handler.ts (SSE 스트림 관리)

// 진행 상황 업데이트에 사용될 데이터 타입 정의 (예시)
interface ProgressUpdateData {
  type: "stage" | "progress" | "complete" | "error" | "info";
  message?: string;
  stage?: "collecting" | "generating" | "finalizing";
  percentage?: number;
  currentPage?: number;
  collectedItems?: number;
  hasNext?: boolean;
  elapsedTime?: number;
  fileData?: string; // Base64 인코딩된 파일 데이터
  dataType?: "excel" | "csv";
  error?: string;
}

export class EventStreamHandler {
  private textEncoder: TextEncoder;
  private streamController: ReadableStreamDefaultController;

  constructor(controller: ReadableStreamDefaultController) {
    this.textEncoder = new TextEncoder();
    this.streamController = controller;
  }

  // 클라이언트에 진행 상황 데이터 푸시
  publish(data: ProgressUpdateData): void {
    const message = `data: ${JSON.stringify(data)}\n\n`;
    this.streamController.enqueue(this.textEncoder.encode(message));
  }

  // 스트림 종료
  close(): void {
    this.streamController.close();
  }

  // SSE 응답 헤더 설정
  static createResponse(stream: ReadableStream): Response {
    return new Response(stream, {
      headers: {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
      },
    });
  }
}

// SSE 스트림을 쉽게 생성할 수 있도록 래핑
export function initializeSSEStream(
  handler: (eventStreamHandler: EventStreamHandler) => Promise<void>
): Response {
  const stream = new ReadableStream({
    async start(controller) {
      const eventStreamHandler = new EventStreamHandler(controller);
      try {
        // 실제 작업 로직을 비동기로 실행하고, 핸들러를 통해 진행 상황을 푸시
        await handler(eventStreamHandler);
      } catch (error) {
        eventStreamHandler.publish({
          type: "error",
          message: "처리 중 오류가 발생했습니다.",
          error: error instanceof Error ? error.message : String(error),
        });
      } finally {
        eventStreamHandler.close(); // 작업 완료 또는 오류 발생 시 스트림 종료
      }
    },
  });
  return EventStreamHandler.createResponse(stream);
}
```

`initializeSSEStream` 함수는 `ReadableStream`을 생성하고, 여기에 `EventStreamHandler`를 주입하여 개발자가 쉽게 SSE 이벤트를 `publish`할 수 있도록 돕습니다. `publish` 메서드는 클라이언트가 `EventSource`를 통해 수신할 `data: JSON_STRING\n\n` 형태의 메시지를 생성하고 스트림에 추가합니다. 이 유틸리티 덕분에 각 Route Handler는 SSE 구현의 세부 사항에 신경 쓸 필요 없이 핵심 로직에만 집중할 수 있게 되었습니다. 에러 처리와 스트림 종료도 `finally` 블록에서 일관되게 관리됩니다.

### 견고한 데이터 수집을 위한 유틸리티: `data-fetcher.ts`

대용량 데이터를 페이징 방식으로 수집하는 과정은 네트워크 지연이나 DB 부하로 인해 불안정해질 수 있습니다. 이를 해결하기 위해 `data-fetcher.ts` 모듈에 페이징 처리, 의도적인 지연, 그리고 재시도 로직을 통합했습니다.

```typescript
// libs/excel/data-fetcher.ts (페이징 데이터 수집 및 재시도 로직)

const DataFetchSettings = {
  BATCH_SIZE: 50, // N페이지마다 긴 대기
  SHORT_DELAY: 10, // 매 페이지마다 짧은 대기 (밀리초)
  LONG_DELAY: 500, // 배치마다 긴 대기 (밀리초)
  MAX_RETRIES: 3, // 최대 재시도 횟수
  RETRY_DELAY: 1000, // 재시도 대기 시간 (밀리초)
};

// 페이징된 데이터를 모두 가져오기 (진행상황 전송 및 재시도 포함)
export async function fetchPaginatedData(
  dataRetrievalFunction: (params: any) => Promise<any>,
  requestParameters: Record<string, any>,
  eventStreamHandler: EventStreamHandler, // SSE 핸들러를 받아 진행 상황 푸시
  options?: { itemsPerPage?: number; outputType?: string }
): Promise<any[]> {
  const allCollectedData: any[] = [];
  let hasMoreData = true;
  let currentPage = 0;
  const itemsPerPage = options?.itemsPerPage || 200;
  const operationStartTime = Date.now();

  const { BATCH_SIZE, SHORT_DELAY, LONG_DELAY, MAX_RETRIES, RETRY_DELAY } =
    DataFetchSettings;

  while (hasMoreData) {
    let attemptCount = 0;
    let successfulFetch = false;
    while (attemptCount < MAX_RETRIES && !successfulFetch) {
      try {
        const result = await dataRetrievalFunction({
          // 인자로 받은 조회 함수 호출
          ...requestParameters,
          page: currentPage.toString(),
          itemsPerPage: itemsPerPage.toString(),
          ...(options?.outputType && { outputType: options.outputType }),
        });
        const currentElements = result?.elements ?? result?.items ?? [];
        hasMoreData = result?.hasNext ?? false;
        allCollectedData.push(...currentElements);

        eventStreamHandler.publish({
          // SSE 핸들러를 통해 진행 상황 푸시
          type: "progress",
          currentPage: currentPage + 1,
          collectedItems: allCollectedData.length,
          hasNext: hasMoreData,
          elapsedTime: Math.floor((Date.now() - operationStartTime) / 1000),
        });

        successfulFetch = true;
        currentPage++;
        if (hasMoreData && currentPage % BATCH_SIZE === 0) {
          // 일정 배치마다 긴 지연을 두어 DB 부하를 줄임
          await new Promise((resolve) => setTimeout(resolve, LONG_DELAY));
        } else if (hasMoreData) {
          // 매 페이지마다 짧은 지연을 두어 연속적인 DB 요청 완화
          await new Promise((resolve) => setTimeout(resolve, SHORT_DELAY));
        }
      } catch (error) {
        attemptCount++;
        if (attemptCount < MAX_RETRIES) {
          eventStreamHandler.publish({
            type: "info",
            message: `페이지 ${
              currentPage + 1
            } 데이터 조회 실패, 재시도합니다...`,
          });
          // 재시도 횟수에 따라 지연 시간을 늘려 부하를 점진적으로 줄임
          await new Promise((resolve) =>
            setTimeout(resolve, RETRY_DELAY * attemptCount)
          );
        } else {
          eventStreamHandler.publish({
            type: "error",
            message: `페이지 ${
              currentPage + 1
            } 데이터 조회 실패 (최대 재시도 횟수 초과)`,
          });
          throw error;
        }
      }
    }
  }
  return allCollectedData;
}
```

`fetchPaginatedData` 함수는 외부에서 전달받은 `dataRetrievalFunction`을 사용하여 데이터를 페이징 방식으로 조회합니다. 이 함수는 `while` 루프를 통해 `hasMoreData`가 `false`가 될 때까지 데이터를 계속 가져옵니다. 각 페이지를 가져올 때마다 `EventStreamHandler`를 통해 진행 상황을 클라이언트에 푸시하여 사용자에게 투명성을 제공합니다. 특히 눈여겨볼 점은 `DataFetchSettings`에 정의된 `SHORT_DELAY`, `LONG_DELAY`를 통해 DB에 대한 연속적인 요청을 완화하고, `MAX_RETRIES`, `RETRY_DELAY`를 통해 일시적인 오류 발생 시 자동으로 재시도를 수행하여 데이터 수집의 안정성을 크게 높였다는 것입니다.

## 클라이언트 API 호출 방식 변경

클라이언트 컴포넌트(`ExcelDownloadInitiator`로 일반화)에서도 서버 API 엔드포인트가 모듈화된 만큼 호출 방식이 변경되었습니다.

```javascript
// components/ExcelDownloadInitiator.js

const EndpointConfigurations = {
  typeA: {
    title: "엑셀 다운로드",
    type: "excel",
    filename: `typeA_records_${todayDate}`,
    disabled: !query.begin && !query.end,
  },
  // ... 기타 다운로드 타입 설정 ...
};

const startDownloadWithProgress = () => {
  setIsLoading(true);
  setError(null);
  setProgress(0);
  setStepMessage("");
  setDownloadComplete(false);

  // 단일 엔드포인트를 호출하며 type으로 다운로드 타입 지정
  const url = `/api/download?type=${props.downloadType}&dateFilter=${requestParameters.current.yearMonth}`;
  const abortController = new AbortController();
  setCurrentAbortController(abortController);

  const eventSource = new EventSource(url, { signal: abortController.signal });

  eventSource.onmessage = (event) => {
    /* ... SSE 이벤트 처리 로직 ... */
  };
  eventSource.onerror = (event) => {
    /* ... 에러 처리 ... */
  };
  eventSource.onopen = () => {
    /* ... 연결 열림 처리 ... */
  };
};
```

이전에는 `props.downloadType` 값을 쿼리 파라미터로 넘겨 단일 엔드포인트 `/api/ex-download`를 호출했습니다. 이는 서버 측에서 `pathname`을 파싱하여 동적으로 로직을 분기하는 복잡성을 야기했습니다.

```javascript
// components/ExcelDownloadInitiator.js

const EndpointConfigurations = {
  typeA: {
    api: "/api/excel/typeA",
    title: "엑셀 다운로드",
    type: "excel",
    filename: `typeA_records_${todayDate}`,
    disabled: !query.begin && !query.end,
  },
  typeA_csv: {
    api: "/api/excel/typeA-csv",
    title: "CSV 다운로드",
    type: "csv",
    filename: `typeA_records_${todayDate}`,
    disabled: !query.begin && !query.end,
  },
  // ... 기타 다운로드 타입 설정 ...
};

const startDownloadWithProgress = () => {
  setIsLoading(true);
  setError(null);
  setProgress(0);
  setStepMessage("");
  setDownloadComplete(false);

  const config = EndpointConfigurations[props.downloadType];

  if (!config || !config.api) {
    console.error(`알 수 없는 다운로드 타입: ${props.downloadType}`);
    alert(`엑셀 다운로드 타입을 찾을 수 없습니다: ${props.downloadType}`);
    setIsLoading(false);
    return;
  }

  // 각 다운로드 타입에 맞는 전용 API 엔드포인트를 직접 호출
  const url = config.api; // 직접 엔드포인트 URL 사용
  const abortController = new AbortController();
  setCurrentAbortController(abortController);

  const eventSource = new EventSource(url, { signal: abortController.signal });

  eventSource.onmessage = (event) => {
    /* ... SSE 이벤트 처리 로직 ... */
  };
  eventSource.onerror = (event) => {
    /* ... 에러 처리 ... */
  };
  eventSource.onopen = () => {
    /* ... 연결 열림 처리 ... */
  };
};
```

변경 후에는 `EndpointConfigurations` 객체에 각 `downloadType`에 해당하는 전용 API 엔드포인트 URL을 직접 명시하고, 클라이언트는 이를 호출합니다. 이렇게 함으로써 엔드포인트의 명확성이 높아지고 서버 라우팅 로직이 간소화되었습니다. 새로운 엑셀 타입이 추가되어도 서버에 해당 Route Handler만 생성하고 클라이언트 `EndpointConfigurations`에 추가하면 되므로, 확장성도 크게 향상되었습니다.

## 결과 및 효과

이번 대용량 엑셀 다운로드 기능 리팩토링은 사용자 경험과 시스템 운영 효율성 두 가지 측면에서 상당한 개선을 이루어냈습니다.

### 사용자 경험 측면

1.  **처리 속도 대폭 향상**: 기존 클라이언트 사이드 방식에서는 엑셀 파일 생성에 평균 20초가 소요되었으나, 서버 사이드로 전환한 후 약 7초로 단축되어 약 3배 가까이 빨라졌습니다. 이로 인해 대기 시간이 크게 줄고, 사용자 만족도가 높아졌습니다.
2.  **실시간 진행률 안내**: SSE 도입으로 "데이터 수집 중", "파일 생성 중", "완료" 등 상세한 진행 상태를 사용자에게 실시간으로 제공할 수 있게 되었습니다. 더 이상 흰 화면을 보며 막연히 기다릴 필요가 없어졌고, 작업이 잘 진행되고 있음을 시각적으로 확인할 수 있어 사용자 만족도가 크게 향상되었습니다.
3.  **안정적인 다운로드**: 브라우저 메모리 폭증 문제가 해결되면서, 대용량 파일도 안정적으로 다운로드할 수 있게 되었습니다. 모바일이나 저사양 PC 환경에서도 문제없이 작동하며, 데이터 수집 과정의 재시도 로직 덕분에 일시적인 네트워크 문제에도 강해졌습니다.
4.  **명확한 에러 안내**: 서버에서 발생하는 오류를 SSE를 통해 즉시 클라이언트에 전달하고, 사용자에게 명확한 에러 메시지를 보여줄 수 있게 되어 문제 발생 시 대처가 용이해졌습니다.

### 시스템 운영 및 개발 효율성 측면

1.  **모놀리식 코드의 해체와 유지보수성 향상**: 2500줄 이상의 단일 파일에 집중되어 있던 로직을 여러 개의 독립적인 Route Handler와 재사용 가능한 유틸리티 모듈로 분리하면서 코드 응집도는 높아지고 결합도는 낮아졌습니다. 각 모듈의 책임이 명확해져 특정 기능을 수정하거나 새로운 다운로드 타입을 추가할 때 다른 코드에 미치는 영향을 최소화하고 개발 효율성을 높일 수 있었습니다.
2.  **서버 부하 분산 및 안정성 확보**: 대용량 데이터 처리의 부담을 클라이언트에서 서버로 이전하면서 브라우저의 리소스 소모를 줄였습니다. 또한, `data-fetcher` 모듈의 페이징, 지연, 재시도 로직 덕분에 데이터베이스에 대한 과도한 요청을 제어하고, 일시적인 장애에도 견고하게 대응할 수 있는 시스템이 구축되었습니다.
3.  **TypeScript 도입과 코드 품질 향상**: 핵심 로직을 TypeScript로 재작성하고 공통 유틸리티를 모듈화하여 컴파일 시점에서 타입 오류를 방지하고 코드의 안정성을 높였습니다. 이는 장기적인 유지보수 비용 절감에도 기여할 것입니다.
4.  **로깅 및 모니터링 용이**: 모든 엑셀 생성 작업이 서버에서 이루어지므로, 작업 시작, 진행, 완료, 에러 등 모든 단계를 서버 로그에 기록하고 모니터링할 수 있게 되었습니다. 이를 통해 문제 발생 시 빠르게 원인을 파악하고 대응할 수 있는 운영 환경이 마련되었습니다.

## 배운 점 및 다음 단계

이번 리팩토링은 단순히 기능을 개선하는 것을 넘어, 대용량 트래픽과 데이터를 다루는 시스템을 설계하고 구현하는 과정에서 많은 것을 배우는 기회였습니다. 모놀리식 코드의 한계를 직접 경험하고, 모듈화와 책임 분리의 중요성을 다시 한번 깨달았습니다. 또한, 사용자 경험을 고려한 실시간 피드백 시스템(SSE)이 기술적 난이도에 비해 사용자 만족도를 크게 높일 수 있다는 것을 확인했습니다.

특히 이번 경험을 통해, 서버에서 대용량 엑셀 파일을 생성하는 작업은 시간이 오래 걸릴 수밖에 없다는 점을 체감했습니다. 이러한 장시간 작업의 진행 상황을 실시간으로 사용자에게 투명하게 알리기 위해 SSE(Server-Sent Events) 기반의 스트리밍 방식을 도입한 것이 큰 효과를 보았습니다. 앞으로는 엑셀 생성이 완료된 후, 파일을 바이너리 스트림으로 직접 내려받게 하거나, S3와 같은 외부 스토리지에 업로드한 뒤 다운로드 URL을 제공하는 방식 등으로 확장해 나갈 계획입니다. 이를 통해 초대용량 파일 처리와 사용자 경험을 더욱 개선할 수 있을 것으로 기대합니다.

기술적인 문제를 해결하는 과정은 언제나 도전적이지만, 사용자에게 더 나은 경험을 제공하고 시스템을 더욱 견고하게 만들어가는 보람찬 여정임을 다시 한번 느꼈습니다.

## 참고 자료

- [MDN Web Docs - Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-Sent_Events)
- [Next.js Documentation - Route Handlers](https://nextjs.org/docs/app/building-your-application/routing/route-handlers)
- [ExcelJS GitHub Repository](https://github.com/exceljs/exceljs)
